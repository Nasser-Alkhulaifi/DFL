{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import gurobipy as gp\n",
    "from gurobipy import Model, quicksum, GRB\n",
    "import time\n",
    "import pyepo\n",
    "from pyepo.model.grb import optGrbModel\n",
    "from pyepo.data.dataset import optDataset\n",
    "from pyepo.func import SPOPlus\n",
    "from pyepo.metric import regret  # Import the regret metric from PyEPO\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)                    # Sets seed for Python's built-in random module\n",
    "    np.random.seed(seed)                 # Sets seed for NumPy's random number generator\n",
    "    torch.manual_seed(seed)              # Sets seed for PyTorch's CPU operations\n",
    "    torch.cuda.manual_seed_all(seed)     # Sets seed for PyTorch's GPU operations\n",
    "    \n",
    "    # Make sure to disable CuDNN's non-deterministic optimizations\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# the dataset has hourly data from 1 jan2024 to 24Feb2025 (2025 data will be used for tese in the final run = 54 days). \n",
    "test_size = 14 #in days - establishes the train/test split (each day has 24 hours/samples)\n",
    "walk_forward_steps = 14 #in days - controls the evaluation process length (each day has 24 hours)\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "# Data class for battery parameters\n",
    "class Data:\n",
    "    def __init__(self, intervals, max_charge, max_discharge, initial_energy_level, battery_capacity, minimum_SoC):\n",
    "        self.intervals = intervals\n",
    "        self.max_charge = max_charge\n",
    "        self.max_discharge = max_discharge\n",
    "        self.initial_energy_level = initial_energy_level\n",
    "        self.battery_capacity = battery_capacity\n",
    "        self.minimum_SoC = minimum_SoC\n",
    "\n",
    "############## Optimisation Model ##############\n",
    "# Battery scheduling optimization model\n",
    "class BatteryScheduling(optGrbModel):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        super().__init__()\n",
    "\n",
    "    def _getModel(self):\n",
    "        m = gp.Model(\"batteryModel\")\n",
    "        m.setParam(\"OutputFlag\", 0)\n",
    "        intervals = self.data.intervals\n",
    "\n",
    "        #BIGM = 99999999  # A large constant used to control constraints logically\n",
    "        \n",
    "        #### Decision variables ####\n",
    "        g = m.addVars(intervals, vtype=GRB.CONTINUOUS, name=\"g\")  # Amount of energy sent from grid to Home at interval t\n",
    "        b = m.addVars(intervals, vtype=GRB.CONTINUOUS, name=\"b\")  # Amount of Energy sent from Battery (discharge) to Home at interval t\n",
    "        c = m.addVars(intervals, vtype=GRB.CONTINUOUS, name=\"c\")  # Amount of Energy sent from Grid to Battery (charge) at interval t\n",
    "        z = m.addVars(intervals, vtype=gp.GRB.BINARY, name=\"z\")  # Charge/discharge switch (Binary flag: battery discharged at interval t)\n",
    "        energy_level = m.addVars(range(intervals + 1), lb=0, ub=self.data.battery_capacity, name=\"energy_level_kwh\") # Battery energy level at each interval\n",
    "        \n",
    "        ##### Constraints ####\n",
    "        # Ensure total energy supply (grid + battery) meets or exceeds demand at every interval\n",
    "        # Logical constraints linking continuous variables to their binary flags\n",
    "        # Logical constraints linking continuous variables to their binary flags\n",
    "        #m.addConstrs(g[t] <= BIGM * y[t] for t in data.intervals)\n",
    "        #Ensure the initial battery level at interval 0\n",
    "        # Battery charge and discharge dynamics across intervals\n",
    "        # Battery cannot discharge more than its current energy level\n",
    "        # Battery cannot charge and discharge simultaneously at the same interval\n",
    "        # Battery physical constraints: max charge/discharge and capacity limits\n",
    "        #Energy level of the battery can not exceed the battery capacity at any interval.\n",
    "        # Energy level of the battery can not exceed the battery capacity at any interval.\n",
    "        self.demand_constrs = m.addConstrs((g[t] + b[t] >= 0 for t in range(intervals)), name=\"demand\")\n",
    "        m.addConstrs(b[t] <= self.data.max_discharge * z[t] for t in range(intervals))\n",
    "        m.addConstr(energy_level[0] == self.data.initial_energy_level)\n",
    "        m.addConstrs(energy_level[t + 1] == energy_level[t] + c[t] - b[t] for t in range(intervals))\n",
    "        m.addConstrs(b[t] <= energy_level[t] for t in range(intervals))\n",
    "        m.addConstrs(c[t] <= self.data.max_charge * (1 - z[t]) for t in range(intervals))\n",
    "        m.addConstrs(energy_level[t] >= self.data.battery_capacity * self.data.minimum_SoC for t in range(intervals + 1))\n",
    "        \n",
    "        #### Objective function #### : minimise cost of energy purchased from grid and a minimal penalty for battery usage\n",
    "        m.setObjective(0, gp.GRB.MINIMIZE)\n",
    "        self._vars = [g[t] for t in range(intervals)] + [b[t] for t in range(intervals)] + [c[t] for t in range(intervals)]\n",
    "        return m, self._vars\n",
    "\n",
    "    def setDemand(self, demand):\n",
    "        \"\"\"Set demand constraints using predicted/actual demand values\"\"\"\n",
    "        for t in range(self.data.intervals):\n",
    "            self.demand_constrs[t].RHS = max(demand[t], 0)\n",
    "\n",
    "    def setObj(self, cost):\n",
    "        \"\"\"Set objective with cost vector for [grid power, battery discharge, battery charge]\"\"\"\n",
    "        m = self._model\n",
    "        if len(cost) == self.data.intervals:\n",
    "            # If only price vector is provided, expand it to full cost vector format\n",
    "            intervals = self.data.intervals\n",
    "            full_cost = np.concatenate([cost, np.zeros(intervals), cost])\n",
    "            m.setObjective(gp.quicksum(full_cost[i] * self._vars[i] for i in range(len(self._vars))), gp.GRB.MINIMIZE)\n",
    "        else:\n",
    "            # Full cost vector is already provided\n",
    "            m.setObjective(gp.quicksum(cost[i] * self._vars[i] for i in range(len(self._vars))), gp.GRB.MINIMIZE)\n",
    "\n",
    "\n",
    "    #### Solve optimisation model ####\n",
    "    def solve(self):\n",
    "        \"\"\"Solve the optimization model and return solution and objective value\"\"\"\n",
    "        self._model.optimize()\n",
    "        if self._model.status == gp.GRB.OPTIMAL:\n",
    "            sol = [var.x for var in self._vars]\n",
    "            obj = self._model.objVal\n",
    "            return sol, obj\n",
    "        else:\n",
    "            # If no optimal solution found, return a default solution\n",
    "            intervals = self.data.intervals\n",
    "            default_sol = [max(self.demand_constrs[t].RHS, 0) for t in range(intervals)] + [0] * (2 * intervals)\n",
    "            default_obj = sum(default_sol[t] * (self._model.getObjective().getVar(t).obj if t < intervals else 0) for t in range(intervals))\n",
    "            return default_sol, default_obj\n",
    "\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "\n",
    "############## MLP model to predict both price and demand ##############\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim=48):  # Output both price and demand (24+24=48)\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return self.relu(x)  \n",
    "\n",
    "# This class wraps our combined model to extract only price predictions for regret calculation (to make it work with PyEPO)\n",
    "class PriceModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = self.model(x)\n",
    "        # Extract only price predictions (first 24 values)\n",
    "        return outputs[:, :24]\n",
    "\n",
    "# Prepare data with sliding windows (creates the feature window, using the previous 24 hours of data to predict the next 24 hours)\n",
    "def prepare_data(df, lookback=24, step=24):\n",
    "    \"\"\"\n",
    "    Create sliding window data from time series with a specified step size\n",
    "    Returns:\n",
    "        - x: Input features (lookback window)\n",
    "        - demand: True demand values for each window\n",
    "        - price: True price values for each window\n",
    "        - cost: Full cost vectors\n",
    "        - timestamps: Timestamps for each window\n",
    "    \"\"\"\n",
    "    x, demand, price, timestamps = [], [], [], []\n",
    "    for t in range(lookback, len(df) - 24 + 1, step):\n",
    "        # Extract lookback window for features\n",
    "        # feature_cols = [col for col in df.columns if col not in ['Demand', 'Price']]\n",
    "        # x_t = df[feature_cols].iloc[t - lookback:t].values.flatten()\n",
    "        \n",
    "        # Include ALL columns for lookback period (including yesterday's Demand and Price)\n",
    "        feature_cols = df.columns\n",
    "        x_t = df[df.columns].iloc[t - lookback:t].values.flatten()\n",
    "        \n",
    "        # Extract next 24 hours for targets\n",
    "        demand_t = df['Demand'].iloc[t:t + 24].values #Target - Next 24 hours of Demand\n",
    "        price_t = df['Price'].iloc[t:t + 24].values   # Target - Next 24 hours of Price\n",
    "        timestamps_t = df.index[t:t + 24]\n",
    "\n",
    "        # Double-Check Features/targets\n",
    "        #print(f\"Features from {df.index[t - lookback]} to {df.index[t - 1]}\")\n",
    "        #print(f\"Targets from {df.index[t]} to {df.index[t + 23]}\")\n",
    "        #Print details for the first window only to Double-Check Features/targets\n",
    "        np.set_printoptions(suppress=True, precision=4) #control how numbers are printed\n",
    "        if t == lookback:\n",
    "            print(f\"Features from {df.index[t - lookback]} to {df.index[t - 1]}\")\n",
    "            print(f\"Feature values (first 30): {x_t[:30]}... (total {len(x_t)} values)\")\n",
    "            print(f\"Targets (Demand) from {df.index[t]} to {df.index[t + 23]}\")\n",
    "            print(f\"Demand target values (first 30): {demand_t[:30]}...\")\n",
    "            print(f\"Targets (Price) from {df.index[t]} to {df.index[t + 23]}\")\n",
    "            print(f\"Price target values (first 30): {price_t[:30]}...\")\n",
    "        \n",
    "        x.append(x_t)\n",
    "        demand.append(demand_t)\n",
    "        price.append(price_t)\n",
    "        timestamps.append(timestamps_t)\n",
    "    \n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    demand = np.array(demand, dtype=np.float32)\n",
    "    price = np.array(price, dtype=np.float32)\n",
    "    # Create cost vectors by combining price with zeros for battery discharge\n",
    "    cost = np.concatenate([price, np.zeros_like(price), price], axis=1)\n",
    "    return x, demand, price, cost, timestamps\n",
    "\n",
    "# Compute true solutions using actual data\n",
    "def compute_true_solutions(optmodel, demand_data, cost_data):\n",
    "    \"\"\"Calculate optimal solutions using true demand and price values\"\"\"\n",
    "    w_true, z_true = [], []\n",
    "    for demand_t, cost_t in zip(demand_data, cost_data):\n",
    "        optmodel.setDemand(demand_t)\n",
    "        optmodel.setObj(cost_t)\n",
    "        sol, obj = optmodel.solve()\n",
    "        w_true.append(sol)\n",
    "        z_true.append(obj)\n",
    "    return np.array(w_true), np.array(z_true)\n",
    "\n",
    "############## Training function with detailed metrics ##############\n",
    "def train_model(reg, func, method_name, train_loader, train_full_loader, train_data, test_data, \n",
    "                optmodel, device, step, epochs=1, window_size=None):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model with detailed metrics tracking\n",
    "    Args:\n",
    "        reg: Neural network model\n",
    "        func: Loss function (varies by method)\n",
    "        method_name: Name of the method (2-Stage, SPO+, DBB) ---->> based on PyEOP API\n",
    "        train_loader: DataLoader for PyEPO methods\n",
    "        train_full_loader: DataLoader for 2-Stage method\n",
    "        train_data: Tuple of (x_train, demand_train, price_train, cost_train)\n",
    "        test_data: Tuple of (x_test, demand_test, price_test, cost_test)\n",
    "        optmodel: Battery scheduling optimisation model\n",
    "        device: Computing device (CPU/GPU)\n",
    "        step: Current step in walk-forward evaluation (1 step = 24 hours = 1 day)\n",
    "        epochs: Number of training epochs\n",
    "        window_size: Size of training window (each window is 24 hours = 1 day)\n",
    "    Returns:\n",
    "        epoch_metrics: Dictionary with detailed metrics for each epoch\n",
    "        predictions: Price and demand predictions\n",
    "        final_test_regret: Test regret after training\n",
    "        total_time: Total training time\n",
    "    \"\"\"\n",
    "    # Unpack test_data to get x_test first\n",
    "    x_test, demand_test, price_test, cost_test = test_data\n",
    "    \n",
    "    print(f\"\\nTraining {method_name} for step {step+1} of {walk_forward_steps}\")\n",
    "    print(f\"Training set: {window_size} samples, Test set: {len(x_test)} samples\")\n",
    "    \n",
    "    # Initialize metrics tracking\n",
    "    epoch_metrics = {\n",
    "        'Method': [],\n",
    "        'Step': [],\n",
    "        'Window_Size': [],\n",
    "        'Epoch': [],\n",
    "        'Train_Regret': [],\n",
    "        'Test_Regret': [],\n",
    "        'Epoch_Time': []\n",
    "    }\n",
    "    \n",
    "    x_train, demand_train, price_train, cost_train = train_data\n",
    "    x_test, demand_test, price_test, cost_test = test_data\n",
    "\n",
    "    start_time_total = time.time()\n",
    "       \n",
    "    optimizer = torch.optim.Adam(reg.parameters(), lr=1e-5)\n",
    "    l1 = nn.L1Loss()\n",
    "    l2 = nn.MSELoss()\n",
    "    \n",
    "    # Create dataset for PyEPO's regret calculation\n",
    "    train_opt_dataset = optDataset(optmodel, x_train, cost_train)\n",
    "    train_opt_loader = DataLoader(train_opt_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    test_opt_dataset = optDataset(optmodel, x_test, cost_test)\n",
    "    test_opt_loader = DataLoader(test_opt_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Create a wrapper model that extracts only price predictions for regret calculation\n",
    "    price_model_wrapper = PriceModelWrapper(reg)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        reg.train()\n",
    "        epoch_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        if method_name == \"2-Stage\":\n",
    "            # For 2-Stage, we use MSE on combined price and demand predictions\n",
    "            for x_batch, targets_batch in train_full_loader:\n",
    "                x_batch, targets_batch = x_batch.to(device), targets_batch.to(device)\n",
    "                predictions = reg(x_batch)\n",
    "                loss = func(predictions, targets_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "                batch_count += 1\n",
    "        else:\n",
    "            # For all other methods, use decision-focused training\n",
    "            for batch_idx, (x_batch, c_batch, w_batch, z_batch, true_demand_batch) in enumerate(train_loader):\n",
    "                x_batch, c_batch = x_batch.to(device), c_batch.to(device)\n",
    "                w_batch, z_batch = w_batch.to(device), z_batch.to(device)\n",
    "                true_demand_batch = true_demand_batch.to(device) \n",
    "                # Get model predictions\n",
    "                predictions = reg(x_batch)\n",
    "                price_pred = predictions[:, :24]\n",
    "                demand_pred = predictions[:, 24:]\n",
    "                \n",
    "                # Create cost vector from price predictions\n",
    "                cost_pred = torch.cat([price_pred, torch.zeros_like(price_pred), price_pred], dim=1)\n",
    "                \n",
    "                # Compute loss based on method type\n",
    "                if method_name == \"SPO+\":\n",
    "                    # Need to handle demand predictions separately\n",
    "                    loss = func(cost_pred, c_batch, w_batch, z_batch)\n",
    "                elif method_name == \"DBB\":\n",
    "                    wp = func(cost_pred)\n",
    "                    zp = torch.sum(wp * c_batch, dim=1).view(-1, 1)\n",
    "                    loss = l1(zp, z_batch) # Linear loss (β=1) or L2 Quadratic loss (β=2)\n",
    "                \n",
    "                # Add MSE term for demand accuracy - critical since predicted demand serves as constraints in optimisation\n",
    "                # 0.1: Prioritises decision optimisation over accurate demand prediction\n",
    "                # 0.5: Equal balance between decision quality and demand accuracy\n",
    "                # 0.9: Emphasises accurate demand forecasting over optimal decisions\n",
    "                loss += 0.5 * l2(demand_pred, true_demand_batch)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "                batch_count += 1\n",
    "        \n",
    "        epoch_end = time.time()\n",
    "        epoch_time = epoch_end - epoch_start\n",
    "        \n",
    "        # Calculate regrets after each epoch using PyEPO's regret function\n",
    "        # Set model to eval mode for regret calculation\n",
    "        reg.eval()\n",
    "        price_model_wrapper.eval()\n",
    "        \n",
    "        # Update demand in optimization model before calculating regret\n",
    "        # We need to manually set demand for each sample before regret calculation\n",
    "        # since the PyEPO regret function doesn't handle demand constraints\n",
    "        \n",
    "        # Hack for training regret: We'll calculate it for each sample and take the average\n",
    "        train_regret_vals = []\n",
    "        \n",
    "        # We need to manually calculate regret for each sample to handle demand\n",
    "        for i in range(len(x_train)):\n",
    "            # Create single-sample optimDataset\n",
    "            sample_opt_dataset = optDataset(optmodel, x_train[i:i+1], cost_train[i:i+1])\n",
    "            sample_loader = DataLoader(sample_opt_dataset, batch_size=1, shuffle=False)\n",
    "            \n",
    "            # Set correct demand for this sample\n",
    "            optmodel.setDemand(demand_train[i])\n",
    "            \n",
    "            # Calculate regret using PyEPO's function\n",
    "            train_regret_i = pyepo.metric.regret(price_model_wrapper, optmodel, sample_loader)\n",
    "            train_regret_vals.append(train_regret_i)\n",
    "        \n",
    "        train_regret = np.mean(train_regret_vals)\n",
    "        \n",
    "        # Same for test regret\n",
    "        test_regret_vals = []\n",
    "        test_price_preds = []\n",
    "        test_demand_preds = []\n",
    "        \n",
    "        for i in range(len(x_test)):\n",
    "            # Make predictions for this sample\n",
    "            with torch.no_grad():\n",
    "                outputs = reg(torch.tensor(x_test[i:i+1], dtype=torch.float32).to(device))\n",
    "                price_pred = outputs[0, :24].cpu().numpy()\n",
    "                demand_pred = outputs[0, 24:].cpu().numpy()\n",
    "                test_price_preds.append(price_pred)\n",
    "                test_demand_preds.append(demand_pred)\n",
    "            \n",
    "            # Create single-sample optimDataset\n",
    "            sample_opt_dataset = optDataset(optmodel, x_test[i:i+1], cost_test[i:i+1])\n",
    "            sample_loader = DataLoader(sample_opt_dataset, batch_size=1, shuffle=False)\n",
    "            \n",
    "            # Set correct demand for this sample\n",
    "            optmodel.setDemand(demand_test[i])\n",
    "            \n",
    "            # Calculate regret using PyEPO's function\n",
    "            test_regret_i = pyepo.metric.regret(price_model_wrapper, optmodel, sample_loader)\n",
    "            test_regret_vals.append(test_regret_i)\n",
    "            \n",
    "            if epoch == epochs - 1:  # Print details on last epoch\n",
    "                print(f\"Sample {i}: Regret = {test_regret_i:.4f}\")\n",
    "        \n",
    "        test_regret = np.mean(test_regret_vals)\n",
    "        \n",
    "        avg_loss = epoch_loss / max(1, batch_count)\n",
    "        \n",
    "        # Store epoch metrics\n",
    "        epoch_metrics['Method'].append(method_name)\n",
    "        epoch_metrics['Step'].append(step+1)\n",
    "        epoch_metrics['Window_Size'].append(window_size)\n",
    "        epoch_metrics['Epoch'].append(epoch+1)\n",
    "        epoch_metrics['Train_Regret'].append(train_regret)\n",
    "        epoch_metrics['Test_Regret'].append(test_regret)\n",
    "        epoch_metrics['Epoch_Time'].append(epoch_time)\n",
    "        \n",
    "        if True:  # Always print every epoch\n",
    "            print(f\"Epoch {epoch+1}: Loss {avg_loss:.4f}, Train regret: {train_regret:.4f}, Test regret: {test_regret:.4f}\")\n",
    "    \n",
    "    # Final evaluation - same as last epoch\n",
    "    final_train_regret = train_regret\n",
    "    final_test_regret = test_regret\n",
    "    predictions = (np.array(test_price_preds), np.array(test_demand_preds))\n",
    "    \n",
    "    total_time = time.time() - start_time_total\n",
    "    print(f\"Method {method_name} - Avg Train Regret: {np.mean(epoch_metrics['Train_Regret']):.4f}, Avg Test Regret: {np.mean(epoch_metrics['Test_Regret']):.4f}, Avg Epoch Time: {np.mean(epoch_metrics['Epoch_Time']):.2f}s\")\n",
    "    \n",
    "    return epoch_metrics, predictions, final_test_regret, total_time\n",
    "\n",
    "### RMSE ###\n",
    "def calculate_forecasting_errors(predictions_df):\n",
    "    \"\"\"Calculate RMSE for each method's price and demand predictions\"\"\"\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    metrics = {'Method': []}\n",
    "    \n",
    "    # Extract true values\n",
    "    true_price = predictions_df['True_Price'].values\n",
    "    true_demand = predictions_df['True_Demand'].values\n",
    "    \n",
    "    # Get all method names\n",
    "    method_names = [col.replace('_Price', '') for col in predictions_df.columns \n",
    "                   if col.endswith('_Price') and col != 'True_Price']\n",
    "    \n",
    "    # Calculate RMSE for each method\n",
    "    for method in method_names:\n",
    "        # Get predictions\n",
    "        pred_price = predictions_df[f'{method}_Price'].values\n",
    "        pred_demand = predictions_df[f'{method}_Demand'].values\n",
    "        \n",
    "        # Filter out NaN values\n",
    "        valid_price_idx = ~np.isnan(pred_price)\n",
    "        valid_demand_idx = ~np.isnan(pred_demand)\n",
    "        \n",
    "        # Calculate RMSE using sklearn\n",
    "        price_rmse = np.sqrt(mean_squared_error(true_price[valid_price_idx], \n",
    "                                              pred_price[valid_price_idx])) if any(valid_price_idx) else np.nan\n",
    "        demand_rmse = np.sqrt(mean_squared_error(true_demand[valid_demand_idx], \n",
    "                                               pred_demand[valid_demand_idx])) if any(valid_demand_idx) else np.nan\n",
    "        \n",
    "        # Add to results\n",
    "        metrics['Method'].append(method)\n",
    "        metrics.setdefault('Price_RMSE', []).append(price_rmse)\n",
    "        metrics.setdefault('Demand_RMSE', []).append(demand_rmse)\n",
    "        \n",
    "    # Create DataFrame and save to CSV\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    metrics_df.to_csv('forecasting_errors.csv', index=False)\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "class CustomOptDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, opt_dataset, true_demand):\n",
    "        self.opt_dataset = opt_dataset\n",
    "        self.true_demand = true_demand\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.opt_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, c, w, z = self.opt_dataset[idx]\n",
    "        demand = torch.tensor(self.true_demand[idx], dtype=torch.float32)\n",
    "        return x, c, w, z, demand\n",
    "\n",
    "def main():\n",
    "\n",
    "    set_seeds()\n",
    "\n",
    "    global test_size  # in days\n",
    "    global walk_forward_steps  # in days\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(\"./Data/Demand_Price_1320_withFE.csv\")\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df = df.set_index('Timestamp')\n",
    "    \n",
    "    # Initialize optimization model\n",
    "    optmodel = BatteryScheduling(Data(\n",
    "        intervals=24, max_charge=5, max_discharge=4.5,\n",
    "        initial_energy_level=10, battery_capacity=50, minimum_SoC=0.10\n",
    "    ))\n",
    "    \n",
    "    # Prepare data with sliding windows\n",
    "    lookback = 24\n",
    "    x, demand, price, cost, timestamps = prepare_data(df, lookback, step=24)\n",
    "    \n",
    "    # Use CPU for computation\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    num_processes = 0  # 1 for single-core, 0 for all of cores\n",
    "    \n",
    "    # Define methods to evaluate - 2-Stage, SPO+, and DBB\n",
    "    methods_list = [\n",
    "        (\"2-Stage\", nn.MSELoss()),\n",
    "        (\"SPO+\", pyepo.func.SPOPlus(optmodel, processes=num_processes)),\n",
    "        (\"DBB\", pyepo.func.blackboxOpt(optmodel, processes=num_processes))\n",
    "    ]\n",
    "\n",
    "    # Print experiment configuration\n",
    "    print(f\"\\n=== EXPERIMENT CONFIGURATION ===\")\n",
    "    print(f\"Total data available: {len(df)} hours\")\n",
    "    print(f\"Test size: {test_size} windows\")\n",
    "    print(f\"Walk-forward steps: {walk_forward_steps}\")\n",
    "    print(f\"Lookback window: {lookback} hours\")\n",
    "    print(f\"Number of input features (24 hours lookback * number of columns/features): {lookback * df.shape[1]}\")\n",
    "    print(f\"Methods to evaluate: {len(methods_list)}\")\n",
    "    print(f\"==============================\\n\")    \n",
    "    \n",
    "    total_windows = len(x)\n",
    "    print(f\"Total windows: {total_windows}, Test windows: {test_size}\")\n",
    "\n",
    "    \n",
    "    # Results containers\n",
    "    detailed_results = []\n",
    "    method_summary = []\n",
    "    predictions_data = {}\n",
    "    \n",
    "    # Store all epoch metrics\n",
    "    all_epoch_metrics = {\n",
    "        'Method': [], 'Step': [], 'Window_Size': [], 'Epoch': [],\n",
    "         'Train_Regret': [], 'Test_Regret': [], 'Epoch_Time': []\n",
    "    }\n",
    "    \n",
    "    # Store true values for test set\n",
    "    test_true_values = {\n",
    "        'Timestamp': [], 'True_Price': [], 'True_Demand': []\n",
    "    }\n",
    "    \n",
    "    # Walk-forward evaluation\n",
    "    all_methods = methods_list\n",
    "    \n",
    "    for method_index, (method_name, loss_func) in enumerate(all_methods):\n",
    "        print(f\"\\nEvaluating method: {method_name}\")\n",
    "        method_results = {\n",
    "            'Method': method_name,\n",
    "            'Step': [],\n",
    "            'Window Size': [],\n",
    "            'Test Regret': [],\n",
    "            'Processing Time': []\n",
    "        }\n",
    "        \n",
    "        # Initialise dictionary to store predictions\n",
    "        predictions_data[method_name] = {'Price': [], 'Demand': []}\n",
    "        \n",
    "        for step in range(walk_forward_steps):\n",
    "            # Calculate indices for current walk-forward window\n",
    "            test_window_idx = total_windows - test_size + step\n",
    "            if test_window_idx >= total_windows:\n",
    "                print(f\"Step {step+1}: No more test data available.\")\n",
    "                break\n",
    "                \n",
    "            # Define train and test sets\n",
    "            x_train = x[:test_window_idx]\n",
    "            demand_train = demand[:test_window_idx]\n",
    "            price_train = price[:test_window_idx]\n",
    "            cost_train = cost[:test_window_idx]\n",
    "            \n",
    "            x_test = x[test_window_idx:test_window_idx+1]\n",
    "            demand_test = demand[test_window_idx:test_window_idx+1]\n",
    "            price_test = price[test_window_idx:test_window_idx+1]\n",
    "            cost_test = cost[test_window_idx:test_window_idx+1]\n",
    "            timestamps_test = timestamps[test_window_idx:test_window_idx+1]\n",
    "\n",
    "            # Save the last day's test data for verification\n",
    "            if step == walk_forward_steps - 1 and method_index == 0:\n",
    "                pd.DataFrame({'feature_index': range(len(x_test[0])), 'feature_value': x_test[0], 'timestamp': str(timestamps_test[0][0])}).to_csv('last_day_features.csv', index=False)\n",
    "                pd.DataFrame({'timestamp': timestamps_test[0], 'true_price': price_test[0], 'true_demand': demand_test[0]}).to_csv('last_day_targets.csv', index=False)\n",
    "\n",
    "            \n",
    "            # Store true values for test windows (only once for first method)\n",
    "            if method_index == 0:\n",
    "                for ts, p, d in zip(timestamps_test[0], price_test[0], demand_test[0]):\n",
    "                    test_true_values['Timestamp'].append(ts)\n",
    "                    test_true_values['True_Price'].append(p)\n",
    "                    test_true_values['True_Demand'].append(d)\n",
    "            \n",
    "            # Compute true solutions for dataset preparation\n",
    "            w_train, z_train = compute_true_solutions(optmodel, demand_train, cost_train)\n",
    "            \n",
    "            # Prepare combined price and demand targets for 2-Stage method\n",
    "            combined_targets = np.concatenate([price_train, demand_train], axis=1)\n",
    "            \n",
    "            # Prepare datasets - standard PyEPO dataset for decision-focused methods\n",
    "            opt_dataset = optDataset(optmodel, x_train, cost_train)\n",
    "            \n",
    "            # Create a custom dataset that includes true demand values\n",
    "            train_dataset = CustomOptDataset(opt_dataset, demand_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "            \n",
    "            # Custom dataset for 2-Stage that includes both price and demand targets\n",
    "            train_full_loader = DataLoader(TensorDataset(\n",
    "                torch.tensor(x_train, dtype=torch.float32), \n",
    "                torch.tensor(combined_targets, dtype=torch.float32)\n",
    "            ), batch_size=32)\n",
    "            \n",
    "            # Initialize model - output dimension  48 (24 price + 24 demand)\n",
    "            input_dim = lookback * df.shape[1]\n",
    "            reg = MLP(input_dim=input_dim, hidden_dim1=256, hidden_dim2=128, output_dim=48).to(device)\n",
    "            \n",
    "            # Train and evaluate with detailed metrics\n",
    "            train_data = (x_train, demand_train, price_train, cost_train)\n",
    "            test_data = (x_test, demand_test, price_test, cost_test)\n",
    "            try:\n",
    "                window_size = len(x_train)\n",
    "                epoch_metrics, predictions, test_regret, proc_time = train_model(\n",
    "                    reg, loss_func, method_name, \n",
    "                    train_loader, train_full_loader, \n",
    "                    train_data, test_data, optmodel, device, step,\n",
    "                    epochs=1, window_size=window_size\n",
    "                )\n",
    "                \n",
    "                # Store detailed metrics for all epochs\n",
    "                for key in all_epoch_metrics:\n",
    "                    all_epoch_metrics[key].extend(epoch_metrics[key])\n",
    "                \n",
    "                # Store summary for this step\n",
    "                method_results['Step'].append(step+1)\n",
    "                method_results['Window Size'].append(window_size)\n",
    "                method_results['Test Regret'].append(test_regret)\n",
    "                method_results['Processing Time'].append(proc_time)\n",
    "                \n",
    "                # Store predictions - includes both price and demand\n",
    "                price_pred, demand_pred = predictions\n",
    "                predictions_data[method_name]['Price'].extend(price_pred[0])\n",
    "                predictions_data[method_name]['Demand'].extend(demand_pred[0])\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error training {method_name} at step {step+1}: {e}\")\n",
    "                method_results['Step'].append(step+1)\n",
    "                method_results['Window Size'].append(len(x_train))\n",
    "                method_results['Test Regret'].append(float('nan'))\n",
    "                method_results['Processing Time'].append(float('nan'))\n",
    "                \n",
    "                # Fill with NaN for predictions\n",
    "                predictions_data[method_name]['Price'].extend([float('nan')] * 24)\n",
    "                predictions_data[method_name]['Demand'].extend([float('nan')] * 24)\n",
    "        \n",
    "        # Add the method's results to the overall summary\n",
    "        for i in range(len(method_results['Step'])):\n",
    "            detailed_results.append({\n",
    "                'Method': method_name,\n",
    "                'Step': method_results['Step'][i],\n",
    "                'Window Size': method_results['Window Size'][i],\n",
    "                'Test Regret': method_results['Test Regret'][i],\n",
    "                'Processing Time (s)': method_results['Processing Time'][i]\n",
    "            })\n",
    "        \n",
    "        # Compute method summary\n",
    "        avg_test_regret = np.nanmean(method_results['Test Regret'])\n",
    "        avg_processing_time = np.nanmean(method_results['Processing Time'])\n",
    "        total_processing_time = np.nansum(method_results['Processing Time'])\n",
    "        \n",
    "        method_summary.append({\n",
    "            'Method': method_name,\n",
    "            'Avg Test Regret': avg_test_regret,\n",
    "            'Avg Processing Time (s)': avg_processing_time,\n",
    "            'Total Processing Time (s)': total_processing_time,\n",
    "            'Steps Completed': len(method_results['Step'])\n",
    "        })\n",
    "    \n",
    "    # Create DataFrames for different result types\n",
    "    df_epoch_metrics = pd.DataFrame(all_epoch_metrics)\n",
    "    df_detailed = pd.DataFrame(detailed_results)\n",
    "    df_summary = pd.DataFrame(method_summary)\n",
    "    \n",
    "    # Create predictions DataFrame with true values\n",
    "    df_true_values = pd.DataFrame(test_true_values)\n",
    "    \n",
    "    # Add method predictions for both price and demand\n",
    "    for method_name in predictions_data:\n",
    "        if len(predictions_data[method_name]['Price']) > 0:\n",
    "            df_true_values[f'{method_name}_Price'] = predictions_data[method_name]['Price']\n",
    "            df_true_values[f'{method_name}_Demand'] = predictions_data[method_name]['Demand']\n",
    "    \n",
    "    # Save all DataFrames to CSV\n",
    "    df_epoch_metrics.to_csv('epoch_metrics.csv', index=False)\n",
    "    df_detailed.to_csv('detailed_results.csv', index=False)\n",
    "    df_summary.to_csv('method_summary.csv', index=False)\n",
    "    df_true_values.to_csv('predictions.csv', index=False)\n",
    "\n",
    "    # Calculate forecasting errors (RMSE)\n",
    "    forecasting_errors = calculate_forecasting_errors(df_true_values)\n",
    "    \n",
    "    print(\"\\nResults Summary:\")\n",
    "    print(df_summary.to_string(index=False, float_format=lambda x: f\"{x:.4f}\" if not np.isnan(x) else \"N/A\"))\n",
    "\n",
    "    print(\"\\nForecasting Errors (RMSE):\")\n",
    "    print(forecasting_errors.to_string(index=False, float_format=lambda x: f\"{x:.4f}\" if not np.isnan(x) else \"N/A\"))\n",
    "\n",
    "\n",
    "    print(\"\\nAll results have been saved to CSV files:\")\n",
    "    print(\"- epoch_metrics.csv: Detailed metrics for each epoch\")\n",
    "    print(\"- detailed_results.csv: Results for each method and step\")\n",
    "    print(\"- method_summary.csv: Summary statistics for each method\")\n",
    "    print(\"- predictions.csv: True values and predictions for test windows\")\n",
    "    print(\"- forecasting_errors.csv: RMSE for price and demand predictions\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"epoch_metrics.csv\")\n",
    "\n",
    "\n",
    "# Extract training and test dataset sizes\n",
    "train_sizes = df['Window_Size'].unique()\n",
    "avg_train_size = df['Window_Size'].mean()\n",
    "min_train_size = df['Window_Size'].min()\n",
    "max_train_size = df['Window_Size'].max()\n",
    "\n",
    "\n",
    "# Group by Method and Epoch to handle multiple steps\n",
    "grouped_df = df.groupby(['Method', 'Epoch']).agg({\n",
    "    'Train_Regret': 'mean',\n",
    "    'Test_Regret': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate average regret across all epochs for each method\n",
    "avg_results = grouped_df.groupby('Method').agg({\n",
    "    'Train_Regret': 'mean',\n",
    "    'Test_Regret': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Sort the methods based on average regret across all epochs (lower is better)\n",
    "train_method_order = avg_results.sort_values('Train_Regret')['Method'].tolist()\n",
    "test_method_order = avg_results.sort_values('Test_Regret')['Method'].tolist()\n",
    "\n",
    "# Get the final epoch values for annotation purposes\n",
    "final_epoch = grouped_df['Epoch'].max()\n",
    "final_results = grouped_df[grouped_df['Epoch'] == final_epoch].copy()\n",
    "\n",
    "# Create pivot tables for heatmaps\n",
    "pivot_train = grouped_df.pivot(index='Method', columns='Epoch', values='Train_Regret')\n",
    "pivot_test = grouped_df.pivot(index='Method', columns='Epoch', values='Test_Regret')\n",
    "\n",
    "# Reorder methods based on average performance - each with its own ordering\n",
    "pivot_train = pivot_train.reindex(train_method_order)\n",
    "pivot_test = pivot_test.reindex(test_method_order)\n",
    "\n",
    "# Add ranking to method names - include only average performance\n",
    "train_ranked_methods = [\n",
    "    f\"{i+1}. {method} (avg: {avg_results[avg_results['Method']==method]['Train_Regret'].values[0]:.3f})\" \n",
    "    for i, method in enumerate(train_method_order)\n",
    "]\n",
    "\n",
    "test_ranked_methods = [\n",
    "    f\"{i+1}. {method} (avg: {avg_results[avg_results['Method']==method]['Test_Regret'].values[0]:.3f})\" \n",
    "    for i, method in enumerate(test_method_order)\n",
    "]\n",
    "\n",
    "# Apply the rankings\n",
    "pivot_train.index = train_ranked_methods\n",
    "pivot_test.index = test_ranked_methods\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(30, 14))\n",
    "\n",
    "# Plot Training Regret Heatmap (sorted by average Train Regret)\n",
    "sns.heatmap(\n",
    "    pivot_train, \n",
    "    ax=axes[0], \n",
    "    cmap=\"Greens\", \n",
    "    annot=True, \n",
    "    fmt=\".3f\",\n",
    "    cbar_kws={'label': 'Regret (lower is better)'},\n",
    "    linecolor='white',\n",
    "    linewidths=0.05,\n",
    "    annot_kws={\"size\": 14}\n",
    ")\n",
    "axes[0].patch.set_alpha(0.1)\n",
    "# In walk-forward validation, initial training set = total windows - test_size\n",
    "# Get initial window size (first step)\n",
    "initial_train_windows = df[df['Step'] == 1]['Window_Size'].iloc[0]\n",
    "initial_train_days = int(initial_train_windows / 1)  # Each window is 1 day\n",
    "\n",
    "axes[0].set_title(f\"Train Regret - Initial train set: {initial_train_days} days\", fontsize=20)\n",
    "axes[0].set_ylabel(\"Methods (ranked by average Train Regret)\", fontsize=18)\n",
    "axes[0].set_xlabel(\"Epoch\", fontsize=18)\n",
    "\n",
    "# For training heatmap\n",
    "for label in axes[0].get_yticklabels():\n",
    "    label.set_fontsize(14)\n",
    "    label.set_fontweight('bold')\n",
    "    label.set_rotation(0)\n",
    "\n",
    "# Plot Test Regret Heatmap (sorted by average Test Regret)\n",
    "sns.heatmap(\n",
    "    pivot_test, \n",
    "    ax=axes[1], \n",
    "    cmap=\"Greens\", \n",
    "    annot=True, \n",
    "    fmt=\".3f\",\n",
    "    cbar_kws={'label': 'Regret (lower is better)'},\n",
    "    linecolor='white',\n",
    "    linewidths=0.05,\n",
    "    annot_kws={\"size\": 14}\n",
    ")\n",
    "axes[1].patch.set_alpha(0.5)\n",
    "axes[1].set_title(f\"Test Regret: {test_size} days\", fontsize=20)\n",
    "axes[1].set_ylabel(\"Methods (ranked by average Test Regret)\", fontsize=18)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=18)\n",
    "\n",
    "# For test heatmap\n",
    "for label in axes[1].get_yticklabels():\n",
    "    label.set_fontsize(14)\n",
    "    label.set_fontweight('bold')\n",
    "    label.set_rotation(0)\n",
    "\n",
    "plt.suptitle(\"Method Comparison - Sorted by Average Regret Values Across All Epochs (lower is better)\", fontsize=20)\n",
    "\n",
    "# Add explanation of regret as a text box\n",
    "explanation = (\n",
    "    \"Regret: The absolute difference between the objective value achieved when using predicted prices (with true demand constraints) versus the objective value achieved with true prices (and true demand constraints).\\n\"\n",
    "    \"Formula: regret = cost_with_predicted_prices - cost_with_true_prices\\n\"\n",
    "    \"• Lower values indicate decisions closer to optimal.\\n\"\n",
    "    \"• Higher values indicate more suboptimal decisions.\\n\"\n",
    "    \"• Methods are ranked by their average regret across all test set.\\n\"\n",
    "    \"(The cost in this battery scheduling problem is the minimisation objective, which is calculated as the sum of grid power usage multiplied by electricity prices at each time interval, plus the cost of battery charging.\\n The optimisation model aims to minimise this total cost while satisfying demand and battery constraints.)\"\n",
    ")\n",
    "plt.figtext(0.5, 0.05, explanation, ha=\"center\", fontsize=14, \n",
    "            bbox={\"facecolor\":\"white\", \"alpha\":1, \"pad\":5, \"edgecolor\":\"lightgray\"})\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.15, 1, 0.97])  # Make room for suptitle and explanation\n",
    "plt.savefig('regrets_with_sizes.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"epoch_metrics.csv\")\n",
    "\n",
    "# Print some diagnostic information about the data\n",
    "print(\"Summary of regret values in epoch_metrics.csv:\")\n",
    "print(df.groupby('Method').agg({\n",
    "    'Train_Regret': ['min', 'max', 'mean', 'median', 'count'],\n",
    "    'Test_Regret': ['min', 'max', 'mean', 'median', 'count']\n",
    "}))\n",
    "\n",
    "# Find any extreme values in the Train_Regret column\n",
    "extreme_values = df[df['Train_Regret'] > 10]\n",
    "if not extreme_values.empty:\n",
    "    print(\"\\nExtreme Train_Regret values detected:\")\n",
    "    print(extreme_values[['Method', 'Step', 'Epoch', 'Train_Regret']])\n",
    "\n",
    "# If needed, cap extreme values for visualization purposes\n",
    "if df['Train_Regret'].max() > 10:\n",
    "    print(\"\\nCapping extreme Train_Regret values at 10.0 for visualization\")\n",
    "    df['Train_Regret'] = df['Train_Regret'].clip(upper=10.0)\n",
    "\n",
    "# Extract training and test dataset sizes\n",
    "train_sizes = df['Window_Size'].unique()\n",
    "avg_train_size = df['Window_Size'].mean()\n",
    "min_train_size = df['Window_Size'].min()\n",
    "max_train_size = df['Window_Size'].max()\n",
    "\n",
    "# Use Step instead of Epoch as the grouping factor\n",
    "grouped_df = df.groupby(['Method', 'Step']).agg({\n",
    "    'Train_Regret': 'mean',\n",
    "    'Test_Regret': 'mean',\n",
    "    'Window_Size': 'first'  # Keep window size information\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate average regret across all steps for each method\n",
    "avg_results = grouped_df.groupby('Method').agg({\n",
    "    'Train_Regret': 'mean',\n",
    "    'Test_Regret': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"\\nAverage results across all steps:\")\n",
    "print(avg_results)\n",
    "\n",
    "# Sort the methods based on average regret across all steps (lower is better)\n",
    "train_method_order = avg_results.sort_values('Train_Regret')['Method'].tolist()\n",
    "test_method_order = avg_results.sort_values('Test_Regret')['Method'].tolist()\n",
    "\n",
    "# Create pivot tables for heatmaps\n",
    "pivot_train = grouped_df.pivot(index='Method', columns='Step', values='Train_Regret')\n",
    "pivot_test = grouped_df.pivot(index='Method', columns='Step', values='Test_Regret')\n",
    "\n",
    "# Reorder methods based on average performance - each with its own ordering\n",
    "pivot_train = pivot_train.reindex(train_method_order)\n",
    "pivot_test = pivot_test.reindex(test_method_order)\n",
    "\n",
    "# Add ranking to method names - include only average performance\n",
    "train_ranked_methods = [\n",
    "    f\"{i+1}. {method} (avg: {avg_results[avg_results['Method']==method]['Train_Regret'].values[0]:.3f})\" \n",
    "    for i, method in enumerate(train_method_order)\n",
    "]\n",
    "\n",
    "test_ranked_methods = [\n",
    "    f\"{i+1}. {method} (avg: {avg_results[avg_results['Method']==method]['Test_Regret'].values[0]:.3f})\" \n",
    "    for i, method in enumerate(test_method_order)\n",
    "]\n",
    "\n",
    "# Apply the rankings\n",
    "pivot_train.index = train_ranked_methods\n",
    "pivot_test.index = test_ranked_methods\n",
    "\n",
    "# Extract window sizes for each step to include in the x-axis labels\n",
    "step_window_sizes = grouped_df.groupby('Step')['Window_Size'].first().to_dict()\n",
    "x_labels = [f\"{step} ({size} days)\" for step, size in step_window_sizes.items()]\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(18, 12))\n",
    "\n",
    "# Plot Training Regret Heatmap (sorted by average Train Regret)\n",
    "sns.heatmap(\n",
    "    pivot_train, \n",
    "    ax=axes[0], \n",
    "    cmap=\"Greens\", \n",
    "    annot=True, \n",
    "    fmt=\".3f\",\n",
    "    cbar_kws={'label': 'Regret (lower is better)'},\n",
    "    linecolor='white',\n",
    "    linewidths=0.05,\n",
    "    annot_kws={\"size\": 12}\n",
    ")\n",
    "axes[0].patch.set_alpha(0.1)\n",
    "\n",
    "# Update x-axis labels to include window sizes\n",
    "axes[0].set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "\n",
    "axes[0].set_title(f\"Train Regret by Step (Window Size Increasing)\", fontsize=20)\n",
    "axes[0].set_ylabel(\"Methods (ranked by average Train Regret)\", fontsize=18)\n",
    "axes[0].set_xlabel(\"Step (Window Size in days)\", fontsize=18)\n",
    "\n",
    "# For training heatmap\n",
    "for label in axes[0].get_yticklabels():\n",
    "    label.set_fontsize(14)\n",
    "    label.set_fontweight('bold')\n",
    "    label.set_rotation(0)\n",
    "\n",
    "# Plot Test Regret Heatmap (sorted by average Test Regret)\n",
    "sns.heatmap(\n",
    "    pivot_test, \n",
    "    ax=axes[1], \n",
    "    cmap=\"Greens\", \n",
    "    annot=True, \n",
    "    fmt=\".3f\",\n",
    "    cbar_kws={'label': 'Regret (lower is better)'},\n",
    "    linecolor='white',\n",
    "    linewidths=0.05,\n",
    "    annot_kws={\"size\": 12}\n",
    ")\n",
    "axes[1].patch.set_alpha(0.5)\n",
    "\n",
    "# Update x-axis labels to include window sizes\n",
    "axes[1].set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "\n",
    "# Extract test size from the data if available, otherwise use a default value\n",
    "test_size = 14  # Default value\n",
    "if 'test_size' in globals():\n",
    "    pass  # Use the value from globals\n",
    "elif hasattr(df, 'test_size'):\n",
    "    test_size = df.test_size\n",
    "    \n",
    "axes[1].set_title(f\"Test Regret by Step - Test Size: {test_size} days\", fontsize=20)\n",
    "axes[1].set_ylabel(\"Methods (ranked by average Test Regret)\", fontsize=18)\n",
    "axes[1].set_xlabel(\"Step (Window Size in days)\", fontsize=18)\n",
    "\n",
    "# For test heatmap\n",
    "for label in axes[1].get_yticklabels():\n",
    "    label.set_fontsize(14)\n",
    "    label.set_fontweight('bold')\n",
    "    label.set_rotation(0)\n",
    "\n",
    "plt.suptitle(\"Method Comparison by Step - Sorted by Average Regret Values (lower is better)\", fontsize=20)\n",
    "\n",
    "# Add explanation of regret as a text box\n",
    "explanation = (\n",
    "    \"Regret: The absolute difference between the objective value achieved when using predicted prices (with true demand constraints) versus the objective value achieved with true prices (and true demand constraints).\\n\"\n",
    "    \"Formula: regret = cost_with_predicted_prices - cost_with_true_prices\\n\"\n",
    "    \"• Lower values indicate decisions closer to optimal.\\n\"\n",
    "    \"• Higher values indicate more suboptimal decisions.\\n\"\n",
    "    \"• Methods are ranked by their average regret across all test set.\\n\"\n",
    "    \"(The cost in this battery scheduling problem is the minimisation objective, which is calculated as the sum of grid power usage multiplied by electricity prices at each time interval, plus the cost of battery charging.\\n The optimisation model aims to minimise this total cost while satisfying demand and battery constraints.)\"\n",
    ")\n",
    "plt.figtext(0.5, 0.05, explanation, ha=\"center\", fontsize=14, \n",
    "            bbox={\"facecolor\":\"white\", \"alpha\":1, \"pad\":5, \"edgecolor\":\"lightgray\"})\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.15, 1, 0.97])  # Make room for suptitle and explanation\n",
    "plt.savefig('regrets_by_step.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"epoch_metrics.csv\")\n",
    "\n",
    "# Group by Method and Epoch to handle multiple steps\n",
    "grouped_df = df.groupby(['Method', 'Epoch']).agg({\n",
    "    'Epoch_Time': 'mean'  # Using Epoch_Time instead of regret\n",
    "}).reset_index()\n",
    "\n",
    "# Get the average time across all epochs for each method\n",
    "avg_times = grouped_df.groupby('Method')['Epoch_Time'].mean().reset_index()\n",
    "\n",
    "# Sort the methods by average time (lower is better/faster)\n",
    "method_order = avg_times.sort_values('Epoch_Time')['Method'].tolist()\n",
    "\n",
    "# Create pivot tables for heatmaps with sorted methods\n",
    "pivot_time = grouped_df.pivot(index='Method', columns='Epoch', values='Epoch_Time')\n",
    "\n",
    "# Reorder methods based on performance\n",
    "pivot_time = pivot_time.reindex(method_order)\n",
    "\n",
    "# Add ranking to method names\n",
    "ranked_methods = [\n",
    "    f\"{i+1}. {method} ({avg_times[avg_times['Method'] == method]['Epoch_Time'].values[0]:.4f}s)\"\n",
    "    for i, method in enumerate(method_order)\n",
    "]\n",
    "pivot_time.index = ranked_methods\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Use a different colormap for time (lower is better)\n",
    "sns.heatmap(\n",
    "    pivot_time, \n",
    "    ax=ax, \n",
    "    cmap=\"Greens\",  \n",
    "    annot=True, \n",
    "    fmt=\".4f\",\n",
    "    cbar_kws={'label': 'Processing Time (seconds)'}\n",
    ")\n",
    "\n",
    "# Rotate y-axis labels vertically for readability\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontsize(12)\n",
    "    label.set_fontweight('bold')\n",
    "    label.set_rotation(0)\n",
    "\n",
    "ax.set_title(\"Processing Time per Epoch\", fontsize=16)\n",
    "ax.set_ylabel(\"Methods (ranked by average processing time)\", fontsize=14)\n",
    "ax.set_xlabel(\"Epoch\", fontsize=14)\n",
    "\n",
    "plt.suptitle(\"Method Comparison - Sorted by Average Processing Time (Lower is Faster)\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig('Processing_Time.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('forecasting_errors.csv')\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\n",
    "\n",
    "for ax, col in zip([ax1, ax2], ['Price_RMSE', 'Demand_RMSE']):\n",
    "    bars = ax.bar(df['Method'], df[col], zorder=2, fill=True, color='lightsteelblue', alpha=0.5, edgecolor='black', linewidth=1.2)\n",
    "    ax.set_title(col.replace('_', ' '))\n",
    "    ax.set_ylabel('RMSE - Test Set')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7, zorder=1)\n",
    "    for spine in ['top', 'right', 'left']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(nbins=15))\n",
    "    for bar in bars:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height():.2f}',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('RMSE.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
